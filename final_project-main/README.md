Аналіз Даних (EDA)

Попередня Обробка Даних
Обробка відсутніх значень у даних
У стовпцях download_avg та upload_avg виявлено по 381 порожньому значенню, що становить приблизно 0,5% від усіх даних. Крім того, значення 0 трапляються у 15% та 16% записів відповідно, що вказує на відхилення від нормального розподілу.
Оскільки набір даних містить outliers, використання середнього значення для заміни нулів може спричинити викривлення розподілу. Натомість медіана забезпечує більш надійне та репрезентативне заповнення.
У 'reamining_contract'виявлено 21 572 порожніх значень, що становить приблизно 30% від усіх даних. Під час аналізу було виявлено, що кількість порожніх та нульових значень значно варіюється залежно від комбінації значень у категоріальних стовпцях is_tv_subscriber та is_movie_package_subscriber.
для заповнення пропущених значень було застосовано group-wise mode imputation, тобто медіана розраховувалась окремо для кожної групи. Це дозволить зберегти особливості кожної категорії та покращити якість моделювання.
OR
для заповнення пропущених значень було застосовано метод KNN-імпутації, який шукає схожі записи, щоб оцінити відсутні значення.
цей метод враховує кілька інших ознак при заповненні значень та mozhe допомогти нам уникати припущень 
Цей підхід допомагає зробити заповнення більш точним та адаптованим до структури даних.

Звичайно! Ось короткий і технічно зрозумілий варіант для README-файлу українською:

---

### ⚙️ Нормалізація даних: Стандартизація методом Z-оцінки

Для нормалізації числових змінних було використано стандартизацію (Z-score normalization). Це дозволяє врахувати як перевищення одного значення у змінні, так і велику розкиданість даних. 
 Причини вибору:
- багато значень зосереджені навколо одного числа
- стандартизація і зменшує вплив екстремальних чисел.






Розробка Моделі
Модель  SVM
 
Результати моделі показують, що вона фактично не навчається — вона взагалі не передбачає клас “churn” (1):
Train Accuracy: 0.443
Train Recall: 0.000
Train Precision: 0.000
Train F1: 0.000

Test Accuracy: 0.452
Test Recall: 0.000
Test Precision: 0.000
Test F1: 0.000

0.000 Recall/Precision/F1 ➜ модель не класифікує жоден приклад як "churn" (1). Вона просто всіх відносить до "не churn" (0).
Це класична проблема дисбалансу класів.
SVM не підходить для сильного дисбалансу
Навіть LinearSVC буде навчатися в сторону домінуючого класу. Саме це і сталося.
Висновок:
Наша модель не передбачає клас "churn", бо його замало — і це типова ситуація.
 Найшвидше рішення — class_weight='balanced' або створення штучно збалансованого train.

Модель RNN:
RNN модель розроблена для передбачення відтоку користувачів інтернет-сервісу. Для цього дані були оброблені, видалено пропущені значення, а ознаки нормалізовано за допомогою StandardScaler. Під час навчання модель використовує вхідні дані у вигляді (зразки, ознаки, 1). Структура моделі включає шар SimpleRNN з 32 нейронами та функцією активації tanh, шар Dense з 16 нейронами та функцією активації relu, та вихідний шар з одним нейроном та сигмоїдальною функцією активації. Модель була створена за допомогою оптимізатора Adam, функції втрат binary_crossentropy та метрики accuracy. Процес навчання тривав 20 ітерацій, з використанням пакету розміром 32, при цьому розподіл даних становив 80% для тренування та 20% для тестування. Для оцінки ефективності моделі застосувалися такі показники як точність, F1-ме
трика, матриця помилок та крива ROC. Модель здатна передбачати ймовірність відходу клієнта від сервісу та може бути збережена для майбутнього застосування.

Інтеграція та Виведення Результатів


Контейнеризація
Проєкт контейнеризовано з використанням Docker. Застосовується офіційний базовий образ python:3.11-slim. Dockerfile виконує такі кроки:

Встановлює робочу директорію /app.

Копіює всі файли проєкту в контейнер.

Встановлює залежності з файлу requirements.txt.

Відкриває порт 8501.

Запускає застосунок через streamlit run app.py.

Для запуску застосунку в контейнері:
docker build -t final_project .
docker run -p 8501:8501 final_project

Всі необхідні бібліотеки визначено у requirements.txt. Вони включають:

TensorFlow — для глибокого навчання

Keras — високорівнева бібліотека для нейронних мереж

Scikit-learn — для класичних ML-алгоритмів

Pandas, NumPy — для роботи з даними

Matplotlib — для побудови графіків

Joblib — для збереження моделей

Streamlit — для побудови веб-інтерфейсу
